<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>xinpeng's page</title>
    <link rel="stylesheet" href="assets/css/jemdoc.css", type="text/css" />
</head>
<body>
<div id="layout-content">
    <div id="toptitle">
        <h1 id="xinpeng-chen-s-blog">Xin-Peng Chen  (陈新鹏)</h1>
    </div>
    <table class="imgtable"><tr><td>
        <img src="assets/images/xinpeng_chen_2018.png" alt="weixs" height="160px" />&nbsp;
        <td align="left">
            <a href="https://chenxinpeng.github.io/">Xin-Peng Chen</a>,
            <a href="https://github.com/chenxinpeng">
                <img src="assets/images/github.png" alt="github" width="20px" height="20px" />
            </a>
            <br />  <br />
            M.Phi. in Photogrammetry and Remote Sensing <br />
            Wuhan University <br /><br />
            Email: jschenxinpeng AT gmail DOT com<br /><br />
            <a href="https://chenxinpeng.github.io/publication/CV_Xinpeng_Chen.pdf">My personal resume</a>
        </td>
    </table>
    <h2>Research Interests</h2>
    My research interests lie in the area of deep learning and multimodal learning, specifically for image and language. Currently, I mainly focus on referring expression comprehension.
    <h2>Work Experience</h2>
        Nov. 2016 - Feb. 2017, Research intern, NLP Group, <a href="http://www.hitachi.com/rd/index.html">Hitachi Central Research Laboratory</a>, Tokyo
        <br> Mentor: <a href="https://scholar.google.com/citations?user=LC_x1w4AAAAJ&hl=en">Dr. Bin Tong</a>
        <br> Topic: Video captioning; Image paragraph description; Reinforcement learning for image captioning.
        <br/><br/>
        Mar. 2017 - The Present, Research intern, CV Group, <a href="http://ai.tencent.com/ailab/index.html">Tencent AI Lab</a>, Shenzhen
        <br> Mentor: <a href="http://forestlinma.com/">Dr. Lin Ma</a>, <a href="https://dblp.org/pers/j/Jiang:Wenhao">Dr. Wenhao Jiang</a>, and <a href="http://www.ee.columbia.edu/~wliu/">Dr. Wei Liu</a>
        <br> Topic: Image and video captioning; Large video classification; Referring expression comprehension.
    <h2>Publications</h2>
    <table class="imgtable">
        <tr><td>
            <img src="assets/images/emnlp_2018_tgns.png" alt="EMNLP2018" width="300px" height="200px" />&nbsp;</td>
            <td align="left"><ul>
                <li><p>Temporally Grounding Natural Sentence in Video.
                    <br />Jingyuan Chen, <b>Xinpeng Chen</b>, Lin Ma, Zequn Jie, Tat-Seng Chua
                    <br /><i>Conference on Empirical Methods in Natural Language Processing (<b>EMNLP</b>)</i>, Brussels, Belgium, 2018.</p>
                </li>
            </ul>
            </td>
        </tr>
    </table>
    <table class="imgtable">
        <tr><td>
            <img src="assets/images/ARNet.png" alt="cvpr2018" width="300px" height="180px" />&nbsp;</td>
            <td align="left"><ul>
                <li><p><a href="publication/ARNet.pdf">Regularizing RNNs for Caption Generation by Reconstructing The Past with The Present.</a>
                    <br /><b>Xinpeng Chen</b>, Lin Ma, Wenhao Jiang, Jian Yao, Wei Liu
                    <br /><i>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>)</i>, Salt Lake City, USA, 2018.</p>
                    <a href="https://github.com/chenxinpeng/ARNet">Source Code</a>, <a href="publication/ARNet_poster.pdf">Poster</a>, <a href="https://www.youtube.com/watch?v=qmNtd9JY04s">Video</a>, <a href="publication/ARNet_supplementary_material.pdf">Supplementary File</a>
                </li>
            </ul>
            </td></tr>
    </table>
    <table class="imgtable">
        <tr><td>
            <img src="assets/images/www2018.png" alt="WWW2018" width="300px" height="125px" />&nbsp;</td>
            <td align="left"><ul>
                <li><p><a href="publication/FVAD.pdf">Fine-grained Video Attractiveness Prediction Using Multimodal Deep Learning on a Large Real-World Dataset.</a>
                    <br /><b>Xinpeng Chen</b>, Jingyuan Chen, Lin Ma, Jian Yao, Wei Liu, Jiebo Luo, Tong Zhang
                    <br /><i>The Web Conference (original <b>WWW</b>), The Big Web Track</i>, Lyon, France, 2018.</p>
                    <a href="https://chenxinpeng.github.io/archive/fvad.html">Project Page</a>
                </li>
            </ul>
            </td></tr>
    </table>
    <table class="imgtable">
        <tr><td>
        <img src="assets/images/aaai2018.png" alt="AAAI2018" width="300px" height="125px" />&nbsp;</td>
        <td align="left"><ul>
            <li><p><a href="publication/ltg.pdf">Learning to Guide Decoding for Image Captioning</a>.
                <br />Wenhao Jiang, Lin Ma, <b>Xinpeng Chen</b>, Fumin Shen, Hanwang Zhang, and Wei Liu
                <br /><i>The AAAI Conference on Artificial Intelligence (<b>AAAI</b>)</i>, Louisiana, USA, 2018.</p>
            </li>
        </ul>
        </td></tr>
    </table>
    <table class="imgtable">
        <tr><td>
            <img src="assets/images/youtube8m.png" alt="CVPR2017" width="300px" height="125px" />&nbsp;</td>
            <td align="left"><ul>
                <li><p><a href="publication/youtube8m.pdf">Aggregating Frame-level Features for Large-Scale Video Classification</a>.
                    <br />Shaoxiang Chen, Xi Wang, Yongyi Tang, <b>Xinpeng Chen</b>, Zuxuan Wu, Yugang Jiang
                    <br /><i>YouTube-8M Large-Scale Video Understanding Challenge (<b>CVPR Workshop</b>)</i>, Hawaii, USA, 2017.</p>
                </li>
            </ul>
            </td></tr>
    </table>
    <h2>Miscellaneous</h2>
    <ul>
        <li><a href="publication/master_thesis.pdf">Research on Image Semantic Caption Generation Based on Encoder-Decoder Framework (Master Thesis)</a></li>
    </ul>
    <ul>
        <li>Tensorflow implement of paper: A Hierarchical Approach for Generating Descriptive Image Paragraphs. <a href="https://github.com/chenxinpeng/im2p">[link]</a></li>
    </ul>
    <ul>
        <li>Tensorflow implement of paper: Sequence to Sequence - Video to Text. <a href="https://github.com/chenxinpeng/S2VT">[link]</a></li>
    </ul>
    <ul>
        <li>Tensorflow implement of paper: Optimization of image description metrics using policy gradient methods. <a href="https://github.com/chenxinpeng/Optimization_of_image_description_metrics_using_policy_gradient_methods">[link]</a></li>
    </ul>
    <ul>
        <li>Detecting the text in natural images by SSD (Single Shot Detection). <a href="https://github.com/chenxinpeng/SSD_scene_text_detection">[link]</a></li>
    </ul>

    <p align="right">Last Updated on 9th Seq, 2018</a></p>
    <p align="right">Published with <a href='https://pages.github.com/'>GitHub Pages</a></p>

</div>

<hr>
<div id="clustrmaps-widget"></div><script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=271&t=tt&d=IIDV8Bpcg0SEOwgKzvj2z_f4I3C4OtisvXjn1m0wKEM'></script>
</body>
</html>