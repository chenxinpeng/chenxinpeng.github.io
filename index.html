<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>xinpeng's page</title>
    <link rel="stylesheet" href="assets/css/jemdoc.css", type="text/css" />
</head>
<body>
<div id="layout-content">
    <div id="toptitle">
        <h1 id="xinpeng-chen-s-blog">Xin-Peng Chen  (陈新鹏)</h1>
    </div>
    <table class="imgtable"><tr><td>
        <img src="assets/images/xinpeng_chen_2018.png" alt="weixs" height="200px" />&nbsp;
        <td align="left"><p>
            <a href="https://chenxinpeng.github.io/">Xin-Peng Chen</a>,
            <a href="https://github.com/chenxinpeng">
                <img src="assets/images/github.png" alt="github" width="20px" height="20px" />
            </a>
            <a href="http://blog.csdn.net/u010167269">
                <img src="assets/images/csdn.png" alt="csdn" width="20px" height="20px" />
            </a>
            <a href="https://weibo.com/jschenxinpeng">
                <img src="assets/images/weibo.png" alt="weibo" width="20px" height="20px" />
            </a>
            <a href="https://www.zhihu.com/people/jschenxinpeng">
                <img src="assets/images/zhihu.png" alt="zhihu" width="20px" height="20px" />
            </a> <br />  <br />
            M.Phi. in Photogrammetry and Remote Sensing <br />
            Wuhan University <br /><br />
            Email: jschenxinpeng@gmail.com<br />
        </td>
    </table>
    <h2>Research Interests</h2>
    My research interests include deep learning and computer vision. Currently, I mainly focus on multi-modal tasks.
    Before that, I have explored on the task of image/video captioning and text detection in natural images.
    <h2>Work Experience</h2>
    From Nov. 2016 to Feb. 2017, I was an intern in Central Research Laboratory of <a href="http://www.hitachi.com/rd/index.html">Hitachi</a> in Tokyo, supervised by B. Tong. <br />
    From Mar. 2017 to the present, I am an intern in <a href="http://ai.tencent.com/ailab/index.html">AI Lab</a> of Tencent, supervised by <a href="http://www.ee.cuhk.edu.hk/~lma/">L. Ma.</a> and <a href="http://www.ee.columbia.edu/~wliu/">W. Liu</a> <br />
    <h2>Publications</h2>
    <table class="imgtable">
        <tr><td>
            <img src="assets/images/ARNet.png" alt="cvpr2018" width="300px" height="125px" />&nbsp;</td>
            <td align="left"><ul>
                <li><p><a href="publication/ARNet.pdf">Regularizing RNNs for Caption Generation by Reconstructing The Past with The Present.</a>
                    <br /><b>X.-P. Chen</b>, L. Ma, W.-H. Jiang, J. Yao, W. Liu
                    <br /><i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR'18)</i>, Salt Lake City, USA, 2018.</p>
                    <a href="https://github.com/chenxinpeng/ARNet">Source Code</a>, <a href="publication/ARNet_poster.pdf">Poster</a>, <a href="https://www.youtube.com/watch?v=qmNtd9JY04s">Video</a>
                </li>
            </ul>
            </td></tr>
    </table>
    <table class="imgtable">
        <tr><td>
            <img src="assets/images/www2018.png" alt="WWW2018" width="300px" height="125px" />&nbsp;</td>
            <td align="left"><ul>
                <li><p><a href="publication/FVAD.pdf">Fine-grained Video Attractiveness Prediction Using Multimodal Deep Learning on a Large Real-World Dataset.</a>
                    <br /><b>X.-P. Chen</b>, J.-Y. Chen, L. Ma, J. Yao, W. Liu, J.-B. Luo, T. Zhang
                    <br /><i>Companion of the The Web Conference 2018 on The Web Conference 2018 (WWW'18)</i>, Lyon, France, 2018.</p>
                    <a href="https://chenxinpeng.github.io/archive/fvad.html">Project Page</a>
                </li>
            </ul>
            </td></tr>
    </table>
    <table class="imgtable">
        <tr><td>
        <img src="assets/images/aaai2018.png" alt="AAAI2018" width="300px" height="125px" />&nbsp;</td>
        <td align="left"><ul>
            <li><p><a href="publication/ltg.pdf">Learning to Guide Decoding for Image Captioning</a>.
                <br />W.-H. Jiang, L. Ma, <b>X.-P. Chen</b>, F.-M. Shen, H.-W. Zhang, and W. Liu
                <br /><i>The AAAI Conference on Artificial Intelligence (AAAI'18)</i>, Louisiana, USA, 2018.</p>
            </li>
        </ul>
        </td></tr>
    </table>
    <table class="imgtable">
        <tr><td>
            <img src="assets/images/youtube8m.png" alt="CVPR2017" width="300px" height="125px" />&nbsp;</td>
            <td align="left"><ul>
                <li><p><a href="publication/youtube8m.pdf">Aggregating Frame-level Features for Large-Scale Video Classification</a>.
                    <br />S.-X. Chen, X. Wang, Y.-Y. Tang, <b>X.-P. Chen</b>, Z.-X. Wu, Y.-G. Jiang
                    <br /><i>Workshop on YouTube-8M Large-Scale Video Understanding Challenge (CVPR'17)</i>, Hawaii, USA, 2017.</p>
                </li>
            </ul>
            </td></tr>
    </table>
    <h2>Projects</h2>
    <ul>
        <li>Tensorflow implement of paper: A Hierarchical Approach for Generating Descriptive Image Paragraphs. <a href="https://github.com/chenxinpeng/im2p">[link]</a></li>
    </ul>
    <ul>
        <li>Tensorflow implement of paper: Sequence to Sequence - Video to Text. <a href="https://github.com/chenxinpeng/S2VT">[link]</a></li>
    </ul>
    <ul>
        <li>Tensorflow implement of paper: Optimization of image description metrics using policy gradient methods. <a href="https://github.com/chenxinpeng/Optimization_of_image_description_metrics_using_policy_gradient_methods">[link]</a></li>
    </ul>
    <ul>
        <li>Detecting the text in natural images by SSD (Single Shot Detection). <a href="https://github.com/chenxinpeng/SSD_scene_text_detection">[link]</a></li>
    </ul>
</div>
</body>
</html>